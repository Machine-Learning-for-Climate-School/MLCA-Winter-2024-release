{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15595c9-1350-4425-a170-16c80185ac01",
   "metadata": {},
   "source": [
    "# **Exercise session 2: Convolutional neural network to detect NO$_2$ emissions from satellite data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb82752-d6ce-4e57-97ac-9c39a6af8586",
   "metadata": {},
   "source": [
    "In this exercise session you will train a convolutional neural network (CNN) to detect NO$_2$ plumes from Sentinel-5P TROPOMI instrument. This exercise is designed to be completed on Aalto JupyterHub. Please ensure that your notebook includes all necessary installation commands for any additional libraries your code requires. These commands should be clearly written and integrated within your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb15c2f-df11-465f-9ae0-2c4732277a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a7c52f-33d7-4b75-8a86-9120dcece556",
   "metadata": {},
   "source": [
    "## **Exercise 2.1: Data preparation**\n",
    "\n",
    "In the previous exercise session, you built a small dataset of 20 images containing a plume and 20 images containing no plume. These images have been combined with those from your classmates to form a larger dataset, suitable for training a convolutional neural network (CNN). Your task now is to prepare this dataset for the training process.\n",
    "1. The pixel values in your images should be normalized to have values between 0 and 1. This is a common practice in image processing for neural networks, as it helps with the convergence during training.\n",
    "2. Separate the data into training, validation and test sets:\n",
    "   - **Training set:** Used for training the CNN. Typically, this is the largest portion of the data.\n",
    "   - **Validation set:** Used to tune the hyperparameters and evaluate the models during training.\n",
    "   - **Test set:** Used to test the model after the training process is complete. This set should only be used once to evaluate the final model performance.\n",
    "\n",
    "A common split ratio is 70% training, 15% validation, and 15% test. However, the exact split may depend on the size of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa422bb7-4b64-4ded-81e9-e62249119d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49d927da-69d9-400e-ab25-b35ad50ed75a",
   "metadata": {},
   "source": [
    "## **Exercise 2.2: Build a convolutional neural network model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8e4175-fc6c-4848-a6f3-7f0a0c68270a",
   "metadata": {},
   "source": [
    "Build a basic CNN model using a framework like TensorFlow or PyTorch. You can use [the code from this tutorial](https://www.tensorflow.org/tutorials/images/cnn) for constructing a simple CNN. The model doesn't need to be very deep; a few convolutional layers should be enough. Explain your model construction in your own words.\n",
    "\n",
    "Model structure guidelines (that you can ignore):\n",
    "1. **Input layer:** Your input layer should match the dimensions of your plume images.\n",
    "2. **Convolutional layers:**\n",
    "   - Start with 2-3 convolutional layers.\n",
    "   - Use small filters/kernels (like 3x3 or 5x5) to capture the image features.\n",
    "   - Apply activation functions like ReLU to introduce non-linearity.\n",
    "3. **Pooling layers:** After each convolutional layer, add a pooling layer (like max pooling) to reduce the spatial dimensions of the output volume.\n",
    "4. **Flatten layer:** Flatten the output from the convolutional layers before feeding it into the fully connected layers.\n",
    "5. **Fully connected (dense) layers:**\n",
    "   - A couple of dense layers at the end of the network for classification.\n",
    "   - The last dense layer should have the number of units equal to the number of classes and use a softmax activation function for multi-class classification.\n",
    "6. **Compile the model:**\n",
    "   - Compile the model with an appropriate optimizer (like Adam or SGD).\n",
    "   - Choose a suitable loss function (like binary_crossentropy for binary classification).\n",
    "   - Include accuracy as a metric for model performance evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bcd204-9093-4f03-9a9f-f721fdde1820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3f13568-870d-4bca-9f92-c19a670bed80",
   "metadata": {},
   "source": [
    "## **Exercise 2.3: Train the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0bfe57-eb4b-44d3-a8d4-4acc08e60eb8",
   "metadata": {},
   "source": [
    "1. Use the training and validation data to train the model.\n",
    "2. Monitor the loss and accuracy metrics over epochs to observe the training process.\n",
    "3. Save the model (optional): After training, you can save your model for future use.\n",
    "\n",
    "Things to Monitor:\n",
    "- **Overfitting:** If your model performs well on training data but poorly on validation data, it might be overfitting. Consider using dropout layers or getting more data.\n",
    "- **Underfitting:** If the model performs poorly on both training and validation data, it might be underfitting. Consider adding complexity to your model or training for more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec2215-8259-4e76-858a-ab55d417e283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03269f9e-7e9e-4a1a-8abf-a8bdd79e9b76",
   "metadata": {},
   "source": [
    "## **Exercise 2.4: Model evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e9246-fd78-4750-92e4-7d4cd91e53a9",
   "metadata": {},
   "source": [
    "After training your model, the next step is to evaluate its performance using the test set. This step is crucial to understand how well your model will perform on unseen data. Some common metrics to evaluate a CNN that performs a classification task are\n",
    "- **Accuracy:** Measures the percentage of correctly predicted instances out of all predictions. It's straightforward but can be misleading in cases of class imbalance.\n",
    "- **Precision** (Positive predictive value): The ratio of correctly predicted positive observations to the total predicted positives. It's important when the cost of False Positives is high.\n",
    "- **Recall** (sensitivity, true positive rate): The ratio of correctly predicted positive observations to all actual positives. Crucial when the cost of false negatives is high.\n",
    "- **F1 score:** The weighted average of precision and recall. Useful as a single metric when you need a balance between precision and recall.\n",
    "- **Confusion matrix:** A table layout that allows visualization of the performance of an algorithm. Shows the number of true positives, false positives, true negatives, and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a71e96-3393-42d5-8a46-21db35fda63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "614b8150-39f5-402f-98a4-d61f5a6e05f4",
   "metadata": {},
   "source": [
    "## **Exercise 2.5: Visualization of results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adf9365-5063-4908-95a4-bc8719bc8bb2",
   "metadata": {},
   "source": [
    "Visualize model predictions: Choose a subset of your test dataset and display the images with their predicted and actual labels. This is particularly useful to see how the model performs on individual examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d385d-a9e1-4828-ad43-1f3618aef77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eaaea4a-5543-41aa-afee-35aaa29cd035",
   "metadata": {},
   "source": [
    "## **Exercise 2.6: Test your model on the real world** (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe9664-f2c2-479d-97d8-f856f688b346",
   "metadata": {},
   "source": [
    "1. Pick an area of roughly 500 000 km$^2$ that includes industrial activity, and consider a period of around one month to ensure enough data. Use Copernicus Browser for a preliminar analysis of a good area.\n",
    "2. Retrieve Sentinel-5P NO$_2$ data from that area and that time period.\n",
    "3. Prepare the data to fit your CNN. The images you feed your CNN need to be of size 64x64 pixels. Make sure you retain the coordinates of your data to be able to locate potential power plants or cities later.\n",
    "4. Look for plumes using your trained CNN.\n",
    "5. How many plumes can you find? Can you link them to any known city or power plant?\n",
    "\n",
    "**Note:** You will need to identify cloud covered-areas and exclude them from the dataset. You can also interpolate missing values due to clouds if there are only a few missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc254e-520f-4c10-bd2f-8af9bbef0130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "498cecc0-ccfe-4f7f-8e0f-d3c5be93d748",
   "metadata": {},
   "source": [
    "## **Exercise 2.7: Overview**\n",
    "\n",
    "Reflect on the entire process you've undertaken, from the initial data collection to building and training your machine learning algorithm, and finally evaluating this algorithm in a real-world setting. Which step did you find the most challenging, and why? Additionally, were there any unexpected difficulties or learning experiences along the way? How do you think these challenges could be addressed in future projects? (Imagine this was a task in your job, this is not a question on how to improve homework exercises!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf8958-1157-4a40-b86e-7a57410c5b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8abda1d4-1b87-4271-b023-0f6541c7f127",
   "metadata": {},
   "source": [
    "## **Exercise 2.8: Comparison**\n",
    "Compare your approach for detecting NO$_2$ plumes with the method described in the class-reviewed paper [Automated detection of atmospheric NO$_2$ plumes from satellite data: a tool to help infer anthropogenic combustion emissions.](https://amt.copernicus.org/articles/15/721/2022/). Focus on key differences and similarities in the data processing techniques, CNN architecture, and overall detection strategy. Briefly discuss how these differences might impact the effectiveness of plume detection\n",
    "\n",
    "Discuss how using a plume detection algorithm based on a CNN model can be utilized for climate action. Interpret the results, noting any interesting observations, and suggest potential areas for model improvement. Could other approaches be better for such a task? What steps would you take next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef8b556-2214-4599-9ea2-5cd92dcd4c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenEO",
   "language": "python",
   "name": "openeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
