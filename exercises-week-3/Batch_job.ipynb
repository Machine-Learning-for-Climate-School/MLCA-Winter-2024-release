{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using openEO Batch Jobs To Run Large and Heavy Workflows\n",
    "\n",
    "Source: Copernicus Data Space Ecosystem JupyterHub\n",
    "\n",
    "Most of the simple, basic openEO usage examples show synchronous execution of process graphs:\n",
    "you submit a process graph with a HTTP request and receive the result as direct response of that same request. \n",
    "This is only feasible if the processing doesn’t take too long (a couple of minutes at most).\n",
    "\n",
    "\n",
    "For the heavier work, covering large regions of interest, long time series, more intensive processing, etc, you have to use batch jobs.\n",
    "\n",
    "This notebook shows how to programmatically create and interact with batch job using the openEO Python client library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `openeo` package and establish an authenticated connection to Copernicus Data Space Ecosystem openEO back-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\n",
    "connection.authenticate_oidc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build data cube\n",
    "\n",
    "Start with a simple data cube: small spatiotemporal slice of `SENTINEL2_L2A` data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = connection.load_collection(\n",
    "    \"SENTINEL2_L2A\",\n",
    "    bands=[\"B04\", \"B03\", \"B02\"],\n",
    "    temporal_extent=(\"2022-05-01\", \"2022-05-30\"),\n",
    "    spatial_extent={\n",
    "        \"west\": 3.202609,\n",
    "        \"south\": 51.189474,\n",
    "        \"east\": 3.254708,\n",
    "        \"north\": 51.204641,\n",
    "        \"crs\": \"EPSG:4326\",\n",
    "    },\n",
    "    max_cloud_cover=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up output format to be GeoTIFF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = cube.save_result(format=\"GTiff\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run as Batch Job\n",
    "\n",
    "The easiest way to run our processing as a batch job is using the `execute_batch()` helper,\n",
    "which takes care of creating a batch job, starting it, and keep polling its status until it's finished (or failed).\n",
    "\n",
    "While not necessary, it is recommended to give your batch job a descriptive title so it’s easier to identify in your job listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = cube.execute_batch(title=\"Slice of S2 data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need a bit more control over the lifetime of a batch job, \n",
    "you can do each step manually, e.g. \n",
    "- create a job with `job = cube.create_job()`\n",
    "- start a job with `job.start_job()`\n",
    "- wait until `job.status()` reaches `\"finished\"`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting a Job\n",
    "\n",
    "A batch job on a back-end is fully identified by its job id. In case of the job we created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.job_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's recommended to properly take note of the batch job id.\n",
    "It allows you to “reconnect” to your job (using `connection.job(job_id)`) on the back-end, \n",
    "even if it was created at another time, by another script/notebook or even with another openEO client.\n",
    "\n",
    "\n",
    "A batch job typically takes some time to finish, and you can check its status with the `status()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.status()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch job logs can be fetched with `job.logs()`. If you prefer a graphical, web-based interactive environment to manage and monitor your batch jobs, feel free to switch to an openEO web editor like [openeo.dataspace.copernicus.eu](https://openeo.dataspace.copernicus.eu/) at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.logs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Batch Job Results\n",
    "\n",
    "The result of a finished batch job consists of several elements:\n",
    "- a STAC-compatible description (metadata) of the batch job results\n",
    "- one or more output files (e.g. multiple GeoTIFF or netCDF assets)\n",
    "\n",
    "You can get a handle to these results with  `get_results()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = job.get_results()\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the general case, when you have one or more result files (also called “assets”), the easiest option to download them is using `download_files()` (plural) where you just specify a download folder (otherwise the current working directory will be used by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.download_files(\"output/batch_job\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(6, 4), nrows=2, ncols=2, dpi=90)\n",
    "for i, path in enumerate(sorted(pathlib.Path(\"output/batch_job/\").glob(\"*tif\"))[:4]):\n",
    "    data = rasterio.open(path).read()\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    ax.imshow((data.transpose(1, 2, 0) / 3000).clip(0, 1))\n",
    "    ax.set_title(path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenEO",
   "language": "python",
   "name": "openeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
