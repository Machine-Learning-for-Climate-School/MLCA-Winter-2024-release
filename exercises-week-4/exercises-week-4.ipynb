{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercise session 4: Deep learning algorithms for detecting images from satellite imagery**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Satellite imagery has a strong potential for improving the monitoring of vessel traffic due its global coverage, availability and objectivity. Traditionally, scientists and industry experts in the field have been relying on optical imagery, which is similar to interpreting a photograph (e.g. Sentinel 2 data). Such satellites have wide swath and high resolution but their instruments cannot permeate through the cloud cover. In this exercise, we will build a [Region-based CNN (R-CNN)](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e), an approach introduced in [Girshick et al. (2014)](https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf), to detect vessels from optical satellite images. An R-CNN uses algorithms such as Selective Search to divide an image into regions that most likely contain an object and then uses a CNN to extract the features and an SVM to classify the image. There have been several generations of this algorithm, such as Fast R-CNN and Faster R-CNN algorithm.\n",
    "\n",
    "More recently, data from [Synthetic Aperture Radars (SAR)](https://www.earthdata.nasa.gov/learn/backgrounders/what-is-sar#:~:text=While%20optical%20imagery%20is%20similar,view%20What%20is%20Remote%20Sensing%3F) has become available. The basic idea is that the sensor produces its own active signal and then measures the reflection from the Earth. The benefit of SAR is that the imagery is not affected by clouds, daylight but it is harder to interpret. Such data is available from Sentinel 1. Popular algorithms in vessel detection from SAR-images include constant False-Alarm Rate (CFAR)(see [this github repo for an example of implemention of CFAR](https://github.com/Rc-W024/SAR_Ship_detection_CFAR)) and [Viola & Jones](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf) have been the two most commonly used algorithms in the field due to their accuracy and, in the case of CFAR, high interpretability. However, there is a growing interest in using deep-learning models for vessel detection from SAR images, see [Paolo et al. (2024)](https://doi.org/10.1038/s41586-023-06825-8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is designed to be completed on Aalto JupyterHub. Please ensure that your notebook includes all necessary installation commands for any additional libraries your code requires. These commands should be clearly written and integrated within your notebook. To submit, go to Nbgrader/Assignment List and click submit next to the exercise. \n",
    "All data loaded from Copernicus Dataspace, should be saved to /coursedata/users/$USER folder. Any files that are integral to your submission but cannot be submitted via Nbgrader, should be placed into the /coursedata/users/$USER folder and properly linked to in the notebook.\n",
    "\n",
    "\n",
    "The deadline is Feb 22 at 10:00. We will be grading the submissions as they arrive, so if you submit before the deadline, you will most likely get feedback earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules. If any additional modules need to be installed to run it on Aalto JupyterHub, include all necessary installation commands.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.1 Build the R-CNN model (4 pt)\n",
    "\n",
    "We are going to use R-CNN for vessel detection from optical satellite images. \n",
    "\n",
    "1. Train a CNN to classify satellite images. You can use [part I of this tutorial by Gotam Dahiya](https://www.kaggle.com/code/apollo2506/ship-detection-using-faster-r-cnn-part-1) as inpiration or build your own. Feel free to use CNN for feature extraction and SVM for classification or just a CNN for both extraction and classification. You can train the model either directly on Kaggle (or elsewhere) or in JupyterHub. In the former case, upload the model into your /coursedata/users/$USER folder. The labelled dataset is available in /coursedata/satellite-imagery-of-ships.\n",
    "\n",
    "2. Use Selective Search to detect ships from optical scenes using the CNN model you built. You can use [part II of this tutorial by Gotam Dahiya](https://www.kaggle.com/code/apollo2506/ship-detection-using-faster-r-cnn-part-2) as inspiration, but for this part, include complete code implementation here. The labelled dataset is available in /coursedata/satellite-ships-scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.2 Test your model on real data (3 pt)\n",
    "\n",
    "Pick an area (Paolo et al (2024) can be useful here), make 5 scenes from Sentinel 2 data and test your algorithm on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.3 Uncertainty of the model in Exercises 4.1-2 (3 pt)\n",
    "\n",
    "One concern of using machine learning methods is how to [understand and quantify uncertainty](https://arxiv.org/pdf/2107.03342.pdf). In the case of the model in Ex. 4.1-4.2 uncertainty could come from:\n",
    "- data acquisition, such as the ability of the labelled data to capture the variability of the real world data and possible errors and noise in the images;\n",
    "- design and training, such as errors in model structure and training procedure;\n",
    "- inference, how well the training data (=Ex. 4.1) matches the real world data where the model is applied (e.g., in Ex. 4.2).\n",
    "\n",
    "Discuss uncertainty in the model from Ex. 4.1-2 and possible solutions to decrease it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.5 Compare the approach you took in Ex. 4.1-2 to Paolo et al (2024) (3 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.6 Mapping vessel traffic and climate action (3 pt)\n",
    "Why is mapping of vessel traffic relevant for climate action? How could you use such maps for tracking greenhouse gas emissions? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.7 (Optional) R-CNN for detecting vessel traffic from SAR images (10 bonus pts)\n",
    "\n",
    "Similar to Ex. 4.1, build a R-CNN to detect vessel traffic from SAR images. You can use any of the datasets listed [here](https://github.com/jasonmanesis/Satellite-Imagery-Datasets-Containing-Ships) and also take inspiration from [this code implementation](https://github.com/jasonmanesis/Ship-Detection-on-Remote-Sensing-Synthetic-Aperture-Radar-Data?tab=readme-ov-file). Note that those SAR datasets contain scenes with metafiles identifying the precise location of vessels, so you would need to use this meta data to produce your own labelled dataset for training the classifier. Compare your results to the model from Ex. 4.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
